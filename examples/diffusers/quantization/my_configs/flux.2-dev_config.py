# Auto-generated quantization config for flux.2-dev
# Generated by ModelOpt Automatic Shape Discovery System

import torch.nn as nn
from calib.plugin_calib import PercentileCalibrator

# Model: black-forest-labs/FLUX.2-dev
# Total parameters: 32,223,281,152
# Quantizable layers: 196
# FP4 eligible: 203
# FP8 eligible: 0

NVFP4_E2M1 = {
    "num_bits": (2, 1),
    "block_sizes": {-1: 16, "type": "dynamic", "scale_bits": (4, 3)},
    "enable": True,
}

FP8_E4M3 = {"num_bits": (4, 3), "axis": None}

# Auto-discovered quantization config
AUTO_NVFP4_CONFIG = {
    "quant_cfg": {
        "*time_guidance_embed.timestep_embedder.linear_1*weight_quantizer": NVFP4_E2M1,
        "*time_guidance_embed.timestep_embedder.linear_1*input_quantizer": NVFP4_E2M1,
        "*time_guidance_embed.timestep_embedder.linear_2*weight_quantizer": NVFP4_E2M1,
        "*time_guidance_embed.timestep_embedder.linear_2*input_quantizer": NVFP4_E2M1,
        "*time_guidance_embed.guidance_embedder.linear_1*weight_quantizer": NVFP4_E2M1,
        "*time_guidance_embed.guidance_embedder.linear_1*input_quantizer": NVFP4_E2M1,
        "*time_guidance_embed.guidance_embedder.linear_2*weight_quantizer": NVFP4_E2M1,
        "*time_guidance_embed.guidance_embedder.linear_2*input_quantizer": NVFP4_E2M1,
        "*double_stream_modulation_img.linear*weight_quantizer": NVFP4_E2M1,
        "*double_stream_modulation_img.linear*input_quantizer": NVFP4_E2M1,
        "*double_stream_modulation_txt.linear*weight_quantizer": NVFP4_E2M1,
        "*double_stream_modulation_txt.linear*input_quantizer": NVFP4_E2M1,
        "*single_stream_modulation.linear*weight_quantizer": NVFP4_E2M1,
        "*single_stream_modulation.linear*input_quantizer": NVFP4_E2M1,
        "*x_embedder*weight_quantizer": NVFP4_E2M1,
        "*x_embedder*input_quantizer": NVFP4_E2M1,
        "*context_embedder*weight_quantizer": NVFP4_E2M1,
        "*context_embedder*input_quantizer": NVFP4_E2M1,
        "*transformer_blocks.0.attn.to_q*weight_quantizer": NVFP4_E2M1,
        "*transformer_blocks.0.attn.to_q*input_quantizer": NVFP4_E2M1,
        "*transformer_blocks.0.attn.to_k*weight_quantizer": NVFP4_E2M1,
        "*transformer_blocks.0.attn.to_k*input_quantizer": NVFP4_E2M1,
        "*transformer_blocks.0.attn.to_v*weight_quantizer": NVFP4_E2M1,
        "*transformer_blocks.0.attn.to_v*input_quantizer": NVFP4_E2M1,
        "*transformer_blocks.0.attn.to_out.0*weight_quantizer": NVFP4_E2M1,
        "*transformer_blocks.0.attn.to_out.0*input_quantizer": NVFP4_E2M1,
        "*transformer_blocks.0.attn.add_q_proj*weight_quantizer": NVFP4_E2M1,
        "*transformer_blocks.0.attn.add_q_proj*input_quantizer": NVFP4_E2M1,
        "*transformer_blocks.0.attn.add_k_proj*weight_quantizer": NVFP4_E2M1,
        "*transformer_blocks.0.attn.add_k_proj*input_quantizer": NVFP4_E2M1,
        "*transformer_blocks.0.attn.add_v_proj*weight_quantizer": NVFP4_E2M1,
        "*transformer_blocks.0.attn.add_v_proj*input_quantizer": NVFP4_E2M1,
        "*transformer_blocks.0.attn.to_add_out*weight_quantizer": NVFP4_E2M1,
        "*transformer_blocks.0.attn.to_add_out*input_quantizer": NVFP4_E2M1,
        "*transformer_blocks.0.ff.linear_in*weight_quantizer": NVFP4_E2M1,
        "*transformer_blocks.0.ff.linear_in*input_quantizer": NVFP4_E2M1,
        "*transformer_blocks.0.ff.linear_out*weight_quantizer": NVFP4_E2M1,
        "*transformer_blocks.0.ff.linear_out*input_quantizer": NVFP4_E2M1,
        "*transformer_blocks.0.ff_context.linear_in*weight_quantizer": NVFP4_E2M1,
        "*transformer_blocks.0.ff_context.linear_in*input_quantizer": NVFP4_E2M1,
        "*time_guidance_embed.timestep_embedder.linear_1*": {"enable": False},
        "*time_guidance_embed.timestep_embedder.linear_2*": {"enable": False},
        "*time_guidance_embed.guidance_embedder.linear_1*": {"enable": False},
        "*time_guidance_embed.guidance_embedder.linear_2*": {"enable": False},
        "*x_embedder*": {"enable": False},
        "*context_embedder*": {"enable": False},
        "*norm_out.linear*": {"enable": False},
        "*output_quantizer": {"enable": False},
        "default": {"enable": False},
    },
    "algorithm": "max",
}

def get_auto_config(model_name: str):
    """Get auto-discovered config for model."""
    return AUTO_NVFP4_CONFIG
