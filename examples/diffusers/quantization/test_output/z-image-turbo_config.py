# Auto-generated quantization config for z-image-turbo
# Generated by ModelOpt Automatic Shape Discovery System

import torch.nn as nn
from calib.plugin_calib import PercentileCalibrator

# Model: Tongyi-MAI/Z-Image-Turbo
# Total parameters: 6,154,908,736
# Quantizable layers: 272
# FP4 eligible: 274
# FP8 eligible: 2

NVFP4_E2M1 = {
    "num_bits": (2, 1),
    "block_sizes": {-1: 16, "type": "dynamic", "scale_bits": (4, 3)},
    "enable": True,
}

FP8_E4M3 = {"num_bits": (4, 3), "axis": None}

# Auto-discovered quantization config
AUTO_NVFP4_CONFIG = {
    "quant_cfg": {
        "*all_final_layer.2-1.adaLN_modulation.1*weight_quantizer": NVFP4_E2M1,
        "*all_final_layer.2-1.adaLN_modulation.1*input_quantizer": NVFP4_E2M1,
        "*noise_refiner.0.attention.to_q*weight_quantizer": NVFP4_E2M1,
        "*noise_refiner.0.attention.to_q*input_quantizer": NVFP4_E2M1,
        "*noise_refiner.0.attention.to_k*weight_quantizer": NVFP4_E2M1,
        "*noise_refiner.0.attention.to_k*input_quantizer": NVFP4_E2M1,
        "*noise_refiner.0.attention.to_v*weight_quantizer": NVFP4_E2M1,
        "*noise_refiner.0.attention.to_v*input_quantizer": NVFP4_E2M1,
        "*noise_refiner.0.attention.to_out.0*weight_quantizer": NVFP4_E2M1,
        "*noise_refiner.0.attention.to_out.0*input_quantizer": NVFP4_E2M1,
        "*noise_refiner.0.feed_forward.w1*weight_quantizer": NVFP4_E2M1,
        "*noise_refiner.0.feed_forward.w1*input_quantizer": NVFP4_E2M1,
        "*noise_refiner.0.feed_forward.w2*weight_quantizer": NVFP4_E2M1,
        "*noise_refiner.0.feed_forward.w2*input_quantizer": NVFP4_E2M1,
        "*noise_refiner.0.feed_forward.w3*weight_quantizer": NVFP4_E2M1,
        "*noise_refiner.0.feed_forward.w3*input_quantizer": NVFP4_E2M1,
        "*noise_refiner.0.adaLN_modulation.0*weight_quantizer": NVFP4_E2M1,
        "*noise_refiner.0.adaLN_modulation.0*input_quantizer": NVFP4_E2M1,
        "*noise_refiner.1.attention.to_q*weight_quantizer": NVFP4_E2M1,
        "*noise_refiner.1.attention.to_q*input_quantizer": NVFP4_E2M1,
        "*noise_refiner.1.attention.to_k*weight_quantizer": NVFP4_E2M1,
        "*noise_refiner.1.attention.to_k*input_quantizer": NVFP4_E2M1,
        "*noise_refiner.1.attention.to_v*weight_quantizer": NVFP4_E2M1,
        "*noise_refiner.1.attention.to_v*input_quantizer": NVFP4_E2M1,
        "*noise_refiner.1.attention.to_out.0*weight_quantizer": NVFP4_E2M1,
        "*noise_refiner.1.attention.to_out.0*input_quantizer": NVFP4_E2M1,
        "*noise_refiner.1.feed_forward.w1*weight_quantizer": NVFP4_E2M1,
        "*noise_refiner.1.feed_forward.w1*input_quantizer": NVFP4_E2M1,
        "*noise_refiner.1.feed_forward.w2*weight_quantizer": NVFP4_E2M1,
        "*noise_refiner.1.feed_forward.w2*input_quantizer": NVFP4_E2M1,
        "*noise_refiner.1.feed_forward.w3*weight_quantizer": NVFP4_E2M1,
        "*noise_refiner.1.feed_forward.w3*input_quantizer": NVFP4_E2M1,
        "*noise_refiner.1.adaLN_modulation.0*weight_quantizer": NVFP4_E2M1,
        "*noise_refiner.1.adaLN_modulation.0*input_quantizer": NVFP4_E2M1,
        "*context_refiner.0.attention.to_q*weight_quantizer": NVFP4_E2M1,
        "*context_refiner.0.attention.to_q*input_quantizer": NVFP4_E2M1,
        "*context_refiner.0.attention.to_k*weight_quantizer": NVFP4_E2M1,
        "*context_refiner.0.attention.to_k*input_quantizer": NVFP4_E2M1,
        "*context_refiner.0.attention.to_v*weight_quantizer": NVFP4_E2M1,
        "*context_refiner.0.attention.to_v*input_quantizer": NVFP4_E2M1,
        "*all_x_embedder.2-1*": {"enable": False},
        "*t_embedder.mlp.0*": {"enable": False},
        "*t_embedder.mlp.2*": {"enable": False},
        "*cap_embedder.1*": {"enable": False},
        "*output_quantizer": {"enable": False},
        "default": {"enable": False},
    },
    "algorithm": "max",
}


def get_auto_config(model_name: str):
    """Get auto-discovered config for model."""
    return AUTO_NVFP4_CONFIG
